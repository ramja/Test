{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "\n",
    "Después de haber realizado la comparación de 2 modelos (Knn Classifier  y SVM Classifier) no encontramos suficiente diferencia en el desempeño de estos dos modelos suficiente para seleccionar uno de ellos y desechar otro.\n",
    "\n",
    "En esta sección intentaremos utilizar por lo menos uno de estos modelos ( SVM Classifier ) y aplicarle un proceso de boosting.\n",
    "\n",
    "Asimismo probaremos otro modelo de boosting que no dependa de la dimensionalidad (Random Forest) para comparar los cuatro modelos.\n",
    "\n",
    "Tomaremos el modelo de los cuatro:\n",
    "+ Knn Classifier\n",
    "+ SVM Classifier\n",
    "+ Boost SVM \n",
    "+ Boost RandomForest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import *\n",
    "from rpy2.robjects.packages import importr\n",
    "import rpy2.robjects as ro\n",
    "import pandas.rpy.common as com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ro.r('datos.ori<-read.csv(\"../data/Miroculus.test.csv\", header = FALSE, sep = \",\",  dec=\".\", fill = TRUE)')\n",
    "ro.r('datos<-datos.ori[-1]')\n",
    "ro.r('corr<-cor(datos)')\n",
    "pyCorr=com.load_data('corr')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos nuestros sets de datos:\n",
    "* Train\n",
    "* Valid\n",
    "* Test  \n",
    "\n",
    "De la misma forma que se hizo con los otros modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(2255628424)\n",
    "ro.r('val<-datos.ori[which(datos.ori[\"V1\"]!=\"?\"),]')\n",
    "ro.r('m <- dim(val)[1]')\n",
    "ro.r('testdtlength <- round(m/3)')\n",
    "ro.r('sam <- sample(1:m, size = round(m/3), replace = FALSE, prob = rep(1/m, m)) ')\n",
    "ro.r('datos.train <- val[-sam,]')\n",
    "ro.r('datos.valid <- val[sam,]')\n",
    "pyDatosTrain=com.load_data('datos.train')\n",
    "pyDatosValid=com.load_data('datos.valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Boost SVC\n",
    "Realizaremos un proceso de boost (Adaboost) al modelo previamente definido esperando tener una mejor o por lo menos igual precisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME',\n",
       "          base_estimator=SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.0001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          learning_rate=1.0, n_estimators=20, random_state=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "XLearn = pyDatosTrain.ix[:, pyDatosTrain.columns != 'V1']\n",
    "YLearn = pyDatosTrain['V1']\n",
    "\n",
    "\n",
    "# creamos un modelo de Adaboost para nuestro SVC con los mismos parámetros obtenidos manualmente\n",
    "mod = AdaBoostClassifier(SVC(gamma=.0001, C=1000),\n",
    "                         algorithm=\"SAMME\",\n",
    "                         n_estimators=20)\n",
    "\n",
    "mod.fit(np.asarray(XLearn),np.asarray(YLearn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:     0.8000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "XValid = pyDatosValid.ix[:, pyDatosValid.columns != 'V1']\n",
    "YValid = pyDatosValid['V1']\n",
    "\n",
    "YPredic = mod.predict(np.asarray(XValid))\n",
    "\n",
    "ac=accuracy_score(np.asarray(YValid),YPredic)\n",
    "print(\"Accuracy:\", \"{:10.4f}\".format(ac))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado\n",
    "El proceso de boosting en el modelo de SVM __no__ muestra un aumento en la precisión del modelo (utilizando los mismos parámetros que tuvieron el mejor desempeño)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boost Random Forest\n",
    "Intentaremos ahora entrenar un modelo de Random Forest, basado en teoría de la información realizando un boosting con diferentes parámetros tratando de encontrar un mejor desempeño del logrado hasta ahora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:     0.8667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "XLearn = pyDatosTrain.ix[:, pyDatosTrain.columns != 'V1']\n",
    "YLearn = pyDatosTrain['V1']\n",
    "\n",
    "\n",
    "# Hacemos un un conjunto de entrenamientos con diferentes parámetros y comparamos los resultados\n",
    "acMem=0.0\n",
    "for i in [1,3,5,7,9] : ##max depth\n",
    "    for j in [2,20,200,2000]: #estimators\n",
    "\n",
    "        mod = AdaBoostClassifier(RandomForestClassifier(max_depth=i, n_estimators=j),\n",
    "                                 algorithm=\"SAMME\",\n",
    "                                 n_estimators=100)\n",
    "\n",
    "        mod.fit(np.asarray(XLearn),np.asarray(YLearn))\n",
    "\n",
    "        YPredic = mod.predict(np.asarray(XValid))\n",
    "\n",
    "        ac= accuracy_score(np.asarray(YValid),YPredic)\n",
    "\n",
    "        if (ac > acMem) :\n",
    "            acMem=ac\n",
    "            depthMem=i\n",
    "            estMem=j\n",
    "\n",
    "print(\"Accuracy:\", \"{:10.4f}\".format(ac))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###  Resultado\n",
    "El proceso de boosting con RandomForest __tampoco__ nos muestra una mejor respuesta en cuanto a la precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
